---
layout:     post
title:      "从卷积到傅里叶变换（一）"
subtitle:   "卷积、相关与滤波"
date:       2018-12-12
author:     "柠萌"
header-img: "img/post-bg/post2018121201.jpg"
tags:
    - 信号
    - 数学
---

## 0. 前言

这是上学期期末考试前就想写的一篇文章了，因为之前看某文章时，发现自己对滤波还是有点不太明白，后来才发现是自己没有理解好什么是卷积。但一直拖到今天。

一般来说，在图像处理中，卷积会是这样的含义。一个图像是一个大矩阵，使用一个小矩阵“卷积核”在图像上从左到右从上到下不断移动，每一次对重合部分对应元素相乘后求和，作为输出矩阵中的当前重合部分中心的值。这里有一张很腻害的动图：

![ru]({{ site.baseurl }}/img/in-post/2018121201/img01.gif)
图片来源：[[不定期更新长文]卷积神经网络工作原理研究](https://www.cnblogs.com/TextEditor/p/6667992.html)

这图看起来就很直观了嘛。

可是当你搜索卷积，你就会看到这样的公式：

![ru]({{ site.baseurl }}/img/in-post/2018121201/img02.svg)

这到底是什么鬼啊？

## 1. 卷积

这就是卷积的定义啊，怎么理解？其实很简单，看看左边发现可以看作是自变量t的函数，也就是两个函数的卷积还是函数。

所以这个结果就是t的一个映射，就是说，给定一个t值，就能通过某种方式得到对应的输出值，也就是说我们可以把所有t算出来。

比如我这里画了个图，f(x)是一个高斯函数，g(x)是二次函数的一部分。

![ru]({{ site.baseurl }}/img/in-post/2018121201/img03.png)

我们算卷积是一个函数，不妨先记为y吧，我们算卷积就是要找出这个y的表达式子，或者说，是自变量x到y的映射——每给出一个x，得到一个y。那我们不妨先算一个特殊的x，比如给定x=2：

我们算卷积f*g(x)在x=2时的值，此时x是常数，先不看积分号，发现就是两个函数的乘积：第一个函数是f(x)，第二个函数是g(x)的变形g(2-x)，我用python的matplotlib画出来了，其实就是将函数g(x)沿x轴翻折，然后再将翻折后的函数移动到x=2处，使得原来在原点的位置和当前要计算的自变量取值（x=2）重合。

然后两函数相乘得到新函数f(x)g(2-x)，即图中透明的蓝色。那其实接下来的反常积分就是求新函数与x轴所夹的面积而已啦。计算到的这部分阴影面积就是x=2时卷积函数y的函数值啦。其中g(x)可以称卷积核函数。

![ru]({{ site.baseurl }}/img/in-post/2018121201/img04.png)

然后我们就对所有x都可以按照这个算法算一次，每个x可以得到对应的值y。这个x到y的映射可以看成是函数记作y=(f*g)(x)，这个函数y就是g对f的卷积了。做了个动态图，看起来就是g在f上滑动。

![ru]({{ site.baseurl }}/img/in-post/2018121201/img05.gif)

得到的结果有点奇怪（可能是dx精度的缘故？）。

![ru]({{ site.baseurl }}/img/in-post/2018121201/img06.png)

## 2. 相关

相关包括自相关（Auto-correlation）和互相关函数，互相关函数的定义如下：

![ru]({{ site.baseurl }}/img/in-post/2018121201/img07.svg)

其中\*表示共轭复数，对于实数而言f\*=f.

而自相关就相当于自己跟自己做互相关。

事实上卷积和相关的定义很类似，直观上差别就在于卷积中的g(x)函数水平翻转了。

“相关”的定义在GNSS中也出现过“码相关”。

## 3. 滤波

滤波器 ，是信号处理中的一个概念，是用于去除信号中不想要的成分或者增强所需成分。其中较常听到的有低通滤波器和高通滤波器。

简单来讲，低通滤波器容许低频信号通过，高通滤波器容许高频信号通过。应用到不同领域，这两个概念都分别有一些不同的表达术语，对低通滤波器，在图像处理里，就对应到边缘平滑、图像模糊，在时序预测里可以对应到平滑（比如各种moving average算法）。对高通滤波器，在图像处理里，就对应到边缘提取与边缘增强。

那卷积又跟滤波有啥关系呢？卷积是一种数学方法，用在图像处理里，不但可以做滤波，还可以实现其他目的。

总的来说，滤波是指从信号中剔除特定频率的波的过程，而该过程一般通过卷积来实现。

## 4. 二维卷积

二维卷积是一维卷积的推广，对于图像处理/卷积神经网络（CNN）的“卷积”概念其实是离散的二位卷积，更准确来说，我们一般意义上理解CNN中“卷积”其实是相关，但由于卷积核函数的参数是学习而来的故不影响逻辑。


2018.12.12 于广州
